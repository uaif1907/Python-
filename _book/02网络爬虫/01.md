#### 1. 在 requests 模块中，requests.content 和 requests.text 什么区别
#### 2. 简要写一下 lxml 模块的使用方法框架
#### 3. 说一说 scrapy 的工作流程
```
调度器把requests-->引擎-->下载中间件--->下载器
下载器发送请求，获取响应---->下载中间件---->引擎--->爬虫中间件--->爬虫
爬虫提取url地址，组装成request对象---->爬虫中间件--->引擎--->调度器
爬虫提取数据--->引擎--->管道
管道进行数据的处理和保存
```
#### 4. scrapy 的去重原理
```
1.Scrapy本身自带有一个中间件;
2.scrapy源码中可以找到一个dupefilters.py去重器;
3.需要将dont_filter设置为False开启去重，默认是false去重，改为True,就是没有开启去重；
4 .对于每一个url的请求，调度器都会根据请求得相关信息加密得到一个指纹信息，并且将指纹信息和set()集合中的指纹信息进 行 比对，如果set()集合中已经存在这个数据，就不在将这个Request放入队列中;5.如果set()集合中没有存在这个加密后的数据，就将这个Request对象放入队列中，等待被调度。
```
#### 5. scrapy 中间件有几种类，你用过哪些中间件
#### 6. 你写爬虫的时候都遇到过什么？反爬虫措施，你是怎么解决的？
#### 7. 为什么会用到代理？
```
爬虫会触发服务器的防爬机制，短时间内关闭用户的机器的ip连接，为了完成对目标的获取，则需要不同的ip来完成
```
#### 8. 代理失效了怎么处理？
```
https://baijiahao.baidu.com/s?id=1618299340903906830&wfr=spider&for=pc
1，将代理IP及其协议加载ProxyHandler赋给一个opener_support变量；2，将opener_support加载build_opener方法，创建opener；3，安装开瓶器。具体代码如下：从urllib导入请求def ProxySpider（网址，proxy_ip，标头）：opener_support = request.ProxyHandler（{'http'：proxy_ip}） 开瓶器= request.build_opener（opener_support） request.install_opener（开启） req = request.Request（URL，headers = header）rsp = request.urlopen（req）.read（）返回rsp

```
#### 9. 列出你知道 header 的内容以及信息
```
User-Agent：产生请求的浏览器类型

Accept：client端可识别的内容类型列表

Host：请求的主机名，允许多个域名同处一个ip地址，即虚拟主机
```
#### 10. 说一说打开浏览器访问 www.baidu.com 获取到结果，整个流程。
#### 11. 爬取速度过快出现了验证码怎么处理
#### 12. scrapy 和 scrapy-redis 有什么区别？为什么选择 redis 数据库？
```
1) scrapy是一个Python爬虫框架，爬取效率极高，具有高度定制性，但是不支持分布式。而scrapy-redis一套基于redis数据库、运行在scrapy框架之上的组件，可以让scrapy支持分布式策略，Slaver端共享Master端redis数据库里的item队列、请求队列和请求指纹集合。

2) 为什么选择redis数据库，因为redis支持主从同步，而且数据都是缓存在内存中的，所以基于redis的分布式爬虫，对请求和数据的高频读取效率非常高。
```
#### 13. 分布式爬虫主要解决什么问题
```
1)ip

2)带宽

3）cpu

4）io



```
#### 14. 写爬虫是用多进程好？还是多线程好？为什么？
```
IO密集型代码(文件处理、网络爬虫等)，多线程能够有效提升效率(单线程下有IO操作会进行IO等待，造成不必要的时间浪费，而开启多线程能在线程A等待时，自动切换到线程B，可以不浪费CPU的资源，从而能提升程序执行效率)。在实际的数据采集过程中，既考虑网速和响应的问题，也需要考虑自身机器的硬件情况，来设置多进程或多线程
```
#### 15. 
```
1 正则表达式:模糊匹配解析
2 html.parser:结构化解析
3 Beautiful Soup :结构化解析
4 lxml:结构化解析
```
#### 16. 需要登录的网页，如何解决同时限制 ip，cookie,session（其中有一些是动态生成的）在不使用动态爬取的情况下？
```
https://blog.csdn.net/lbjowen/article/details/82584951
```
<<<<<<< HEAD
#### 17. 验证码的解决（简单的：对图像做处理后可以得到的，困难的：验证码是点击，拖动等动态进行的？）
=======
#### 17. 验证码的解决（简单的：对图像做处理后可以得到的，困难的：验证码是点击，拖动等动态进行的？）

#### 18.请简要介绍下scrapy框架。

#### 19.为什么要使用scrapy框架？scrapy框架有哪些优点？

#### 20.scrapy框架有哪几个组件/模块？简单说一下工作流程。

#### 21. scrapy如何实现分布式抓取？
>>>>>>> f7b6f27b8863281a8d56c664dc37f8d1f9c57d2b
